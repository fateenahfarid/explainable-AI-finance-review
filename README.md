# Explainable AI in Financial Decision-Making: A Scoping Review

## Overview
This repository contains the **final scoping review paper** titled  
**“Explainable Artificial Intelligence in Financial Decision-Making.”**

The review examines how Explainable AI (XAI) techniques are applied in
high-stakes financial decision-making, with a primary focus on **loan approval
and credit risk assessment**. Particular attention is given to post-hoc
explainability methods such as **SHAP** and **LIME**, and their role in improving
model transparency, fairness, and regulatory compliance.

This work was completed as the **final paper** for  
**DS402: Trends in Data Science – Explainable AI** at **Penn State University**.

---

## Academic Context
- **Course:** DS402 – Trends in Data Science (Explainable AI)
- **Institution:** The Pennsylvania State University
- **Project Type:** Final academic scoping review
- **Domain:** Financial machine learning & explainability

The objective of this project was to synthesize recent research (2021–present)
on XAI practices in financial systems and to evaluate how explainability is
operationalized in real-world and regulated decision environments.

---

## Research Questions
This scoping review was guided by the following questions:

- **RQ1:** How are explainable AI techniques applied to financial
decision-making tasks such as loan approval and credit risk assessment?
- **RQ2:** How are explainability methods such as SHAP and LIME evaluated
in financial contexts?
- **RQ3:** What trade-offs between predictive performance, interpretability,
and fairness are reported in existing studies?

---

## Methodology
- Scoping review methodology
- Literature search conducted using **Google Scholar**
- Inclusion of peer-reviewed and academic studies published **from 2021 onward**
- Focus on real-world applications of post-hoc explainability in financial ML
- Comparative synthesis of explainability techniques, evaluation strategies,
and reported trade-offs

---

## Key Themes Identified
- Widespread adoption of **post-hoc explainability** to support black-box
financial models
- SHAP favored for **stable global and local explanations**
- LIME used for **case-level interpretability** in operational settings
- Persistent trade-offs between **model performance, interpretability, and fairness**
- Explainability positioned as a **deployment requirement**, not an optional feature,
in regulated financial systems

---

## Author
**Fateenah Farid**  
Bachelor of Science in Applied Data Sciences
College of Information, Science, and Technology
The Pennsylvania State University
Class of 2026

---

## Notes
This repository represents a completed academic research project and is
maintained for documentation, academic reference, and professional portfolio
purposes. The work highlights research skills in explainable AI, financial
machine learning, and responsible data science.
